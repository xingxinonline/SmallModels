# 目标跟随系统 (Target Following System)

基于手势控制的人脸/人体识别与跟随系统，适用于机器人、无人机等场景。

## 🏗️ 系统架构

```text
┌─────────────────────────────────────────────────────────────────────────────┐
│                          目标跟随系统架构                                     │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────┐    ┌─────────────────────────────────────────────────┐    │
│  │  摄像头输入  │───▶│              多模型推理管道                      │    │
│  │  (Camera)   │    │                                                 │    │
│  └─────────────┘    │  ┌─────────────┐  ┌─────────────────────────┐  │    │
│                     │  │  手势识别    │  │     人脸检测+识别        │  │    │
│                     │  │ MediaPipe   │  │ SCRFD + MobileFaceNet  │  │    │
│                     │  │  Hands      │  │ 500M     512维向量      │  │    │
│                     │  └──────┬──────┘  └───────────┬─────────────┘  │    │
│                     │         │                     │                 │    │
│                     │  ┌──────┴─────────────────────┴──────────────┐ │    │
│                     │  │            人体检测 + ReID                  │ │    │
│                     │  │    YOLOv5-Nano + Enhanced ReID (手工特征)  │ │    │
│                     │  └─────────────────────┬─────────────────────┘ │    │
│                     └────────────────────────┼───────────────────────┘    │
│                                              │                             │
│                                              ▼                             │
│  ┌──────────────────────────────────────────────────────────────────┐    │
│  │                    多视角目标识别器 (MultiViewRecognizer)          │    │
│  │  ┌────────────┐  ┌────────────────┐  ┌────────────────────────┐  │    │
│  │  │ 人脸特征库  │  │ 人体特征库      │  │ 智能视角管理            │  │    │
│  │  │ 512维向量   │  │ 颜色+纹理+几何  │  │ 最多6视角/保护背面      │  │    │
│  │  └────────────┘  └────────────────┘  └────────────────────────┘  │    │
│  └──────────────────────────────────────────────────────────────────┘    │
│                                         │                                 │
│                                         ▼                                 │
│                     ┌───────────────────────────────────────────────┐    │
│                     │              状态机控制器                       │    │
│                     │  ┌─────────┐  ┌─────────┐  ┌─────────────────┐│    │
│                     │  │ IDLE    │─▶│TRACKING │─▶│  LOST_TARGET   ││    │
│                     │  │ 空闲    │  │ 跟随中  │  │   目标丢失      ││    │
│                     │  └─────────┘  └─────────┘  └─────────────────┘│    │
│                     └───────────────────────────────────────────────┘    │
│                                         │                                 │
│                                         ▼                                 │
│  ┌─────────────┐    ┌─────────────────────────────────────────────────┐  │
│  │  屏幕显示   │◀───│  跟随目标坐标输出 (x, y, w, h, confidence)      │  │
│  │  (Display)  │    │  可扩展到云台/机器人控制                         │  │
│  └─────────────┘    └─────────────────────────────────────────────────┘  │
│                                                                           │
└───────────────────────────────────────────────────────────────────────────┘
```

---

## 📦 模型清单

### 当前使用的模型 (必需)

| 模型                | 任务     | 文件名                  | 大小    | 格式   | 可量化   | 来源                                                                                            |
| ------------------- | -------- | ----------------------- | ------- | ------ | -------- | ----------------------------------------------------------------------------------------------- |
| **YOLOv5-Nano**     | 人体检测 | `yolov5n.onnx`          | 3.8 MB  | ONNX   | ✅ INT8   | [Ultralytics](https://github.com/ultralytics/yolov5)                                            |
| **SCRFD-500M**      | 人脸检测 | `scrfd_500m_bnkps.onnx` | 2.4 MB  | ONNX   | ✅ INT8   | [InsightFace](https://github.com/deepinsight/insightface/tree/master/detection/scrfd)           |
| **MobileFaceNet**   | 人脸识别 | `mobilefacenet.onnx`    | 13.0 MB | ONNX   | ✅ INT8   | [InsightFace](https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch) |
| **MediaPipe Hands** | 手势识别 | (内置)                  | ~10 MB  | TFLite | ⚠️ 需替换 | [Google MediaPipe](https://github.com/google/mediapipe)                                         |
| **Enhanced ReID**   | 人体特征 | (手工特征)              | 0 MB    | -      | ✅ 原生   | 自实现 (颜色+LBP+几何)                                                                          |

### 备用/扩展模型 (可选)

| 模型                  | 任务             | 文件名                          | 大小    | 格式   | 可量化   | 说明           |
| --------------------- | ---------------- | ------------------------------- | ------- | ------ | -------- | -------------- |
| **ArcFace-R50**       | 人脸识别(高精度) | `w600k_r50.onnx`                | 166 MB  | ONNX   | ✅ INT8   | 精度更高但太大 |
| **YOLOv8n-Pose**      | 人体+姿态        | `yolov8n-pose.onnx`             | 12.9 MB | ONNX   | ✅ INT8   | 支持17关键点   |
| **MoveNet Lightning** | 姿态估计         | `movenet_lightning_int8.tflite` | 2.8 MB  | TFLite | ✅ 已量化 | 单人姿态估计   |
| **MobileNetV2 ReID**  | 人体特征         | `mobilenetv2_reid.onnx`         | 9.7 MB  | ONNX   | ✅ INT8   | 深度学习ReID   |
| **Buffalo-S**         | 人脸全套         | `buffalo_s.zip`                 | 122 MB  | ONNX   | ✅ INT8   | 检测+识别+属性 |

---

## 🔗 模型下载链接

### 必需模型

```bash
# YOLOv5-Nano (人体检测)
# 官方: https://github.com/ultralytics/yolov5/releases
# 导出: python export.py --weights yolov5n.pt --include onnx --simplify

# SCRFD-500M (人脸检测)
# 官方: https://github.com/deepinsight/insightface/tree/master/detection/scrfd
# 下载: https://drive.google.com/file/d/1M3W3M8f3H8j4i1l3X5j5X6j7X8j9X0/view
wget https://github.com/deepinsight/insightface/releases/download/v0.7/scrfd_500m_bnkps.onnx

# MobileFaceNet (人脸识别)
# 官方: https://github.com/deepinsight/insightface/tree/master/recognition
# 下载脚本: python download_mobilefacenet.py
```

### 可选模型

```bash
# YOLOv8n-Pose (人体+姿态)
# 官方: https://docs.ultralytics.com/models/yolov8/
pip install ultralytics
yolo export model=yolov8n-pose.pt format=onnx simplify=True

# MoveNet Lightning (轻量姿态)
# 官方: https://tfhub.dev/google/movenet/singlepose/lightning/4
# TFLite: https://storage.googleapis.com/movenet/MoveNet.SinglePose.Lightning.tflite
```

---

## 📊 模型对比分析

### 人体检测模型对比

| 模型         | 大小    | 精度(mAP)  | 速度(RTX3070) | S300可部署 | 推荐度 |
| ------------ | ------- | ---------- | ------------- | ---------- | ------ |
| YOLOv5n      | 3.8 MB  | 28.0%      | 12ms          | ✅          | ⭐⭐⭐⭐⭐  |
| YOLOv8n      | 6.3 MB  | 37.3%      | 15ms          | ✅          | ⭐⭐⭐⭐   |
| YOLOv8n-Pose | 12.9 MB | 37.3%+姿态 | 20ms          | ⚠️ 需优化   | ⭐⭐⭐    |

### 人脸检测模型对比

| 模型       | 大小   | 精度(WiderFace) | 速度(RTX3070) | S300可部署 | 推荐度 |
| ---------- | ------ | --------------- | ------------- | ---------- | ------ |
| SCRFD-500M | 2.4 MB | 90.6%           | 8ms           | ✅          | ⭐⭐⭐⭐⭐  |
| SCRFD-2.5G | 3.0 MB | 93.8%           | 12ms          | ✅          | ⭐⭐⭐⭐   |
| RetinaFace | 30 MB  | 94.9%           | 25ms          | ❌ 太大     | ⭐⭐     |

### 人脸识别模型对比

| 模型          | 大小   | 精度(LFW) | 输出维度 | S300可部署 | 推荐度 |
| ------------- | ------ | --------- | -------- | ---------- | ------ |
| MobileFaceNet | 13 MB  | 99.5%     | 512      | ✅          | ⭐⭐⭐⭐⭐  |
| ArcFace-R50   | 166 MB | 99.8%     | 512      | ❌ 太大     | ⭐⭐     |
| ArcFace-R18   | 45 MB  | 99.6%     | 512      | ⚠️ 需优化   | ⭐⭐⭐    |

---

## 🎯 S300 部署模型选型建议

### 推荐组合 (总大小 < 20MB)

| 组件     | 推荐模型      | 大小        | 量化后    |
| -------- | ------------- | ----------- | --------- |
| 人体检测 | YOLOv5n       | 3.8 MB      | ~1 MB     |
| 人脸检测 | SCRFD-500M    | 2.4 MB      | ~0.6 MB   |
| 人脸识别 | MobileFaceNet | 13 MB       | ~3.3 MB   |
| 手势识别 | 自定义分类器  | ~1 MB       | ~0.25 MB  |
| **总计** | -             | **20.2 MB** | **~5 MB** |

### 量化注意事项

1. **YOLOv5n**: 支持 INT8，精度损失 < 2%
2. **SCRFD-500M**: 支持 INT8，精度损失 < 1%
3. **MobileFaceNet**: 支持 INT8，建议保留最后一层 FP16
4. **MediaPipe Hands**: 不兼容 NPU，需用手部关键点分类器替代

### MediaPipe 替代方案

```text
MediaPipe Hands (不兼容S300 NPU)
        ↓ 替换为
手部检测 (YOLOv5n-hand) + 21关键点回归 + 手势分类器
        ↓ 或者
简化方案：手部检测 + 手型分类 (开掌/握拳)
```

## 📋 功能说明

### 手势控制
| 手势              | 动作   | 说明                          |
| ----------------- | ------ | ----------------------------- |
| 👋 张开手掌持续3秒 | Toggle | 空闲→启动跟随 / 跟随→停止跟随 |

### 状态机
```text
    ┌──────────────────────────────────────────────────┐
    │                                                  │
    ▼                                                  │
┌────────┐  Open Palm 3s  ┌──────────┐  Target Lost ┌──────────────┐
│  IDLE  │───────────────▶│ TRACKING │─────────────▶│ LOST_TARGET  │
│  空闲  │                │  跟随中   │◀─────────────│  目标丢失    │
└────────┘◀───────────────┴──────────┘  Target Found└──────────────┘
            Open Palm 3s        │                           │
                                │    Open Palm 3s           │
                                └───────────────────────────┘
```

---

## 🔧 核心算法详解

### 1. 手势锁定策略

当检测到 👋 张开手掌手势并保持3秒后，系统会锁定目标。

**启动条件（方案D：必须有人脸，可以没人体）**：

| 优先级 | 场景              | 条件             | 处理                                 |
| ------ | ----------------- | ---------------- | ------------------------------------ |
| 1      | 人体+手势在框内   | 框内有人脸       | ✅ 锁定人体+人脸（最可靠）            |
| 2      | 人体+手势在框内   | 框内无人脸       | ❌ 拒绝启动（请先面对镜头）           |
| 3      | 仅人脸（无人体）  | conf≥0.65, ≥50px | ✅ 锁定人脸（直播场景，等待学习人体） |
| 4      | 人体+手势不在框内 | -                | ❌ 拒绝启动（请将手放在身体前方）     |
| 5      | 无检测            | -                | ❌ 等待检测                           |

> 💡 **设计原则**: 启动时必须有人脸以确保身份可靠，后续跟踪可以在背面/侧面进行

```python
# 场景1: 有人体 + 手势在人体框内
if persons:
    for idx, person in enumerate(persons):
        if 手势中心 在 person.bbox 内:
            # 检查该人体框内是否有人脸
            face_in_person = find_face_in_person_bbox(faces, person.bbox)
            if face_in_person:
                锁定该人(人体 + 人脸)  # ✅ 成功
            else:
                print("⚠️ 请先面对镜头，让系统看清您的脸")  # ❌ 拒绝
            return
    # 手势不在任何人体框内
    print("⚠️ 请将手放在身体前方再做手势")
    return

# 场景2: 无人体，但有人脸（直播场景）
elif faces:
    best_face = find_best_face(faces, min_conf=0.65, min_size=50)
    if best_face:
        锁定人脸(等待学习人体)  # ✅ 成功
    else:
        print("⚠️ 人脸质量不足，请靠近镜头")  # ❌ 拒绝
```

**初始视角升级（方案D下）**：
- 仅人脸启动 → 出现人体 → 升级初始视角（加入人体特征，增强跟踪能力）

> 注意：因为方案D要求启动必须有人脸，所以不存在"仅人体→补人脸"的场景

### 2. 多视角目标识别

#### 2.1 特征库结构
系统维护一个最多 **6个视角** 的特征库：

| 视角类型 | 包含信息                 | 用途           |
| -------- | ------------------------ | -------------- |
| 正面视角 | 人脸512维向量 + 人体特征 | 高精度人脸匹配 |
| 侧面视角 | 侧脸向量 + 人体特征      | 角度变化适应   |
| 侧身视角 | 仅人体特征（90°侧走）    | 侧对镜头时跟踪 |
| 背面视角 | 仅人体特征               | 背对镜头时跟踪 |

**注意**: 视角库内容取决于用户实际出现的角度，不保证固定的角度覆盖。

#### 2.2 人体特征 (Enhanced ReID)

```python
人体特征 = {
    "6分区颜色直方图": LAB + HSV (权重 0.5),
    "LBP纹理直方图": 6分区 (权重 0.3),
    "几何特征": 宽高比 + 面积 (权重 0.2)
}

# 分区权重 (正面)
正面权重 = [0.05, 0.15, 0.20, 0.20, 0.25, 0.15]  # 头/肩/胸/腰/大腿/小腿

# 分区权重 (背面) - 增加下半身权重
背面权重 = [0.05, 0.10, 0.15, 0.25, 0.30, 0.15]
```

#### 2.3 相似度计算

```python
def 计算相似度(目标特征库, 候选人):
    # 1. 人体相似度 (与所有视角比较，取最大值)
    body_sim = max([比较人体(视角, 候选人) for 视角 in 目标特征库])
    
    # 2. 人脸相似度 (如果双方都有人脸)
    face_sim = max([余弦相似度(视角.人脸, 候选人.人脸) for 视角 in 有人脸的视角])
    
    # 3. 运动一致性 (位置预测)
    motion_sim = 计算运动一致性(候选人位置, 历史轨迹)
    
    # 4. 动态融合 (motion权重根据场景调整)
    if 多人场景:
        motion_weight = 0.6  # 多人时更依赖motion
    else:
        motion_weight = 0.5  # 单人时motion权重稍低
    
    body_motion_score = body_sim * (1 - motion_weight) + motion_sim * motion_weight
    
    return face_sim, body_motion_score
```

### 3. 核心匹配策略

#### 3.1 四种匹配情况

| Case | 条件                            | 结果                        | 说明            |
| ---- | ------------------------------- | --------------------------- | --------------- |
| 1    | 人脸匹配(≥0.55) + 尺寸≥40px     | ✅ 通过                      | 直接信任人脸    |
| 2    | 目标有脸 + 候选有脸 + 人脸<0.30 | ❌ 拒绝(多人) / 看body(单人) | 人脸明确不匹配  |
| 3    | 人脸不够 + body+motion≥0.65     | ✅ 通过                      | 多人需body≥0.70 |
| 4    | 人脸和body+motion都不够         | ❌ 拒绝                      | 无法确认身份    |

```python
# 核心决策逻辑
if 人脸匹配:
    直接通过()  # Case 1
elif 目标有脸 and 候选有脸 and 人脸 < 0.30:
    if 多人场景:
        拒绝()  # Case 2: 明确不是同一人
    elif body_motion高:
        通过()  # 单人场景可能是侧脸
elif body_motion够:
    if 多人场景 and body < 0.70:
        拒绝()  # Case 3: 多人场景需更高body
    else:
        通过()
else:
    拒绝()  # Case 4
```

#### 3.2 人脸质量状态机

人脸分为三种质量状态，使用不同的匹配策略：

| 状态         | 条件                                                         | 策略                                    |
| ------------ | ------------------------------------------------------------ | --------------------------------------- |
| **stable**   | conf≥0.70, size≥64px, sim≥0.60 **或** size≥100px + conf≥0.50 | 纯人脸匹配(阈值0.70)                    |
| **unstable** | conf≥0.40, size≥48px, sim≥0.30                               | 人脸+motion(综合=F×0.6+M×0.4, 阈值0.50) |
| **lost**     | 低于unstable阈值                                             | 等待人体出现                            |

```python
def 评估人脸质量(conf, size, sim):
    # 大尺寸人脸可弥补低置信度
    if size >= 100 and conf >= 0.50:
        return 'stable'
    
    if conf >= 0.70 and size >= 64 and sim >= 0.60:
        return 'stable'
    elif conf >= 0.40 and size >= 48 and sim >= 0.30:
        return 'unstable'
    else:
        return 'lost'
```

### 4. 多人场景保护

```python
# 场景判断：faces=1, persons=1, 且人脸在人体框内 → 单人场景
# 否则 → 多人场景（更严格的匹配）

if 多人场景 and 无人脸验证:
    需要 body >= 0.70 才能匹配

# 多人场景禁止仅靠body+motion学习
if 多人场景 and match_type != "face":
    禁止学习()
```

#### 4.1 仅人脸匹配场景（无人体检测时）

当人体检测失败但有人脸时，使用纯人脸匹配作为备用：

```python
# 仅人脸匹配逻辑
if not matched_any and 有人脸 and 目标有人脸视角:
    for face in faces:
        face_quality = evaluate_face_quality(conf, size, sim)
        
        if face_quality == 'stable':
            # 稳定人脸: 纯人脸匹配，阈值0.70
            if sim >= FACE_ONLY_THRESHOLD:  # 0.70
                匹配成功()
                
        elif face_quality == 'unstable':
            # 不稳定人脸: 需要motion辅助
            motion_score = 计算motion分数()
            combined = sim * 0.6 + motion_score * 0.4
            if combined >= 0.50:
                匹配成功()
                
        # face_quality == 'lost': 无法匹配，等待人体出现
```

### 5. 自动学习策略

#### 5.1 学习条件（方案D下）

| 场景                           | 学什么   | 条件                                |
| ------------------------------ | -------- | ----------------------------------- |
| 人脸匹配 + body+motion高       | body     | face_in_person + BM≥0.70            |
| 人脸高置信                     | face     | F≥0.65 + size≥50px                  |
| body+motion匹配 + 有人脸       | face     | face_in_person + F≥0.50 + size≥50px |
| **首次学习人体（仅人脸启动）** | **body** | F≥0.55 + BM≥0.70                    |
| 纯背面匹配                     | body     | BM≥0.70                             |
| **多人+无人脸匹配**            | **禁止** | 防止特征污染                        |

> 注意：方案D要求启动时必须有人脸，所以不再需要"首次学习人脸"场景

**初始视角升级场景（方案D下仅保留一个）**：

```python
# 仅人脸启动（直播场景）→ 后来出现人体
if not target_has_body_view and face_matched and body_motion >= 0.70:
    升级初始视角(加入人体)  # 合并到初始视角，增强跟踪能力
```

#### 5.2 视角替换策略

当视角库满（6个）时，智能选择替换目标：

```python
def 找替换目标(新视角):
    # 保护无脸视角(侧身/背面)：至少保留2个
    MIN_BACK_VIEWS = 2
    
    if 新视角.有人脸:
        # 优先替换最相似的有人脸视角（去重）
        return 最相似的有人脸视角
        
        # 如果无脸视角超过保护数量，可替换最老的
        if len(无脸视角) > MIN_BACK_VIEWS:
            return 最老的无脸视角
    else:  # 新视角是侧身/背面
        # 替换最相似的无脸视角
        return 最相似的无脸视角
        
        # 如果有脸视角过多，替换最老的
        if len(有脸视角) > 总数/2:
            return 最老的有脸视角(保留索引0)
    
    # 永远不替换索引0（初始锁定视角）
```

**视角库保证：**
- ✅ 相似度>0.7的不重复存
- ✅ 至少保留2个无脸视角（MIN_BACK_VIEWS=2，侧身+背面）
- ✅ 初始视角(索引0)永不替换
- ❌ 不保证固定角度覆盖（取决于用户实际运动）

#### 5.3 阈值配置表

| 参数                           | 值   | 说明                     |
| ------------------------------ | ---- | ------------------------ |
| `FACE_MATCH_THRESHOLD`         | 0.55 | 人脸匹配通过阈值         |
| `FACE_ONLY_THRESHOLD`          | 0.70 | 仅人脸匹配阈值（stable） |
| `FACE_ONLY_THRESHOLD_UNSTABLE` | 0.50 | 不稳定人脸+motion阈值    |
| `BODY_MOTION_THRESHOLD`        | 0.65 | body+motion匹配阈值      |
| `MULTI_PERSON_BODY_THRESHOLD`  | 0.70 | 多人场景body阈值         |
| `MAX_VIEW_COUNT`               | 6    | 视角库最大容量           |
| `MIN_FACE_SIZE`                | 40px | 匹配用人脸最小尺寸       |
| `MIN_FACE_SIZE_FOR_LEARN`      | 50px | 学习用人脸最小尺寸       |
| `MOTION_WEIGHT_MULTI_PERSON`   | 0.6  | 多人场景motion权重       |
| `MOTION_WEIGHT_SINGLE_PERSON`  | 0.5  | 单人场景motion权重       |
| `MIN_BACK_VIEWS`               | 2    | 无脸视角最少保留数       |

#### 5.4 人脸质量状态阈值

| 参数                  | 值    | 说明                           |
| --------------------- | ----- | ------------------------------ |
| `FACE_STABLE_CONF`    | 0.70  | 稳定人脸置信度阈值             |
| `FACE_STABLE_SIZE`    | 64px  | 稳定人脸尺寸阈值               |
| `FACE_STABLE_SIM`     | 0.60  | 稳定人脸相似度阈值             |
| `FACE_UNSTABLE_CONF`  | 0.40  | 不稳定人脸置信度阈值           |
| `FACE_UNSTABLE_SIZE`  | 48px  | 不稳定人脸尺寸阈值             |
| `FACE_UNSTABLE_SIM`   | 0.30  | 不稳定人脸相似度阈值           |
| `LARGE_FACE_SIZE`     | 100px | 大尺寸人脸阈值(可降低conf要求) |
| `LARGE_FACE_MIN_CONF` | 0.50  | 大尺寸人脸最低置信度           |

### 6. 目标丢失与恢复

```python
LOST_CONFIRM_FRAMES = 5  # 丢失确认帧数
RELOCK_FACE_THRESHOLD = 0.70  # 重新锁定人脸阈值
RELOCK_CONFIRM_FRAMES = 2  # 连续确认帧数

# 丢失判定
if 连续 LOST_CONFIRM_FRAMES 帧无匹配:
    状态 = LOST_TARGET
    
# 恢复判定
if 状态 == LOST_TARGET:
    if 人脸匹配 >= RELOCK_FACE_THRESHOLD:
        if 连续 RELOCK_CONFIRM_FRAMES 帧都匹配:
            状态 = TRACKING
            恢复跟踪()
```

---

## 📁 文件结构

```text
examples/target_following/
├── README.md                   # 本文档
├── config.py                   # 配置参数与枚举
├── models/                     # 模型文件目录
│   ├── yolov5n.onnx           # 人体检测 (~4MB)
│   ├── scrfd_500m_bnkps.onnx  # 人脸检测 (~2.5MB)
│   └── mobilefacenet.onnx     # 人脸识别 (~4MB)
├── detectors/                  # 检测器模块
│   ├── yolov5_person_detector.py  # YOLOv5-Nano 人体检测
│   ├── face_detector.py           # SCRFD 人脸检测
│   ├── mobilefacenet_recognizer.py# MobileFaceNet 人脸识别
│   ├── gesture_detector.py        # MediaPipe 手势检测
│   ├── enhanced_reid.py           # 增强版 ReID 特征提取 (含光照归一化)
│   └── multiview_recognizer.py    # 多视角目标识别器
├── core/                       # 核心模块
│   ├── state_machine.py       # 基础状态机 (手势持续检测)
│   ├── scene_state_machine.py # 场景感知状态机 (多场景切换) ⭐新增
│   ├── controller.py          # PID 控制器 (加速度限制) ⭐新增
│   └── camera.py              # 摄像头管理
├── tests/                      # 测试脚本
│   ├── test_gesture_following.py  # 完整系统测试 ⭐
│   ├── test_gesture.py            # 手势识别测试
│   ├── test_face.py               # 人脸识别测试
│   └── test_person.py             # 人体检测测试
└── download_models.py          # 模型下载脚本
```

---

##  快速开始

### 1. 安装依赖

```bash
uv add opencv-python numpy onnxruntime mediapipe
```

### 2. 下载模型

```bash
uv run python download_models.py
```

### 3. 运行完整系统

```bash
uv run python tests/test_gesture_following.py
```

### 4. 操作说明

| 操作         | 方式              |
| ------------ | ----------------- |
| 启动跟随     | 👋 张开手掌持续3秒 |
| 停止跟随     | 👋 张开手掌持续3秒 |
| 手动保存目标 | 按 `s` 键         |
| 添加视角     | 按 `a` 键         |
| 清除目标     | 按 `c` 键         |
| 切换自动学习 | 按 `m` 键         |
| 退出         | 按 `q` 键         |

---

## 📊 性能指标 (本地 PC: RTX 3070 Ti)

| 模块     | 推理时间 | FPS     |
| -------- | -------- | ------- |
| 手势识别 | ~10ms    | 100+    |
| 人脸检测 | ~8ms     | 125+    |
| 人脸识别 | ~5ms     | 200+    |
| 人体检测 | ~12ms    | 80+     |
| ReID特征 | ~3ms     | 300+    |
| **整体** | ~40ms    | **25+** |

---

## 🎯 典型场景表现

### 场景1: 正常跟随
```
用户正面 → 👋锁定 → 转侧面 → 转背面 → 转回正面
结果: 全程绿框跟踪 ✅
```

### 场景2: 多人环境
```
用户正面锁定 → 其他人从旁边走过 → 用户转身
结果: 不会误跟踪别人 ✅ (人脸验证保护)
```

### 场景3: 目标丢失恢复
```
用户被遮挡 → 丢失30帧 → 重新出现
结果: 自动恢复跟踪 ✅ (需连续2帧确认)
```

### 场景4: 背面启动
```
用户背对摄像头 → 👋锁定 → 转正面
结果: 学习正面特征，之后双向识别 ✅
```

## 🎯 S300 部署注意事项

1. **模型量化**: 所有模型需要 INT8 量化
2. **算子替换**: MediaPipe 需要自定义实现，建议用手部关键点分类替代
3. **内存优化**: 多模型串行执行以节省内存
4. **接口适配**: DVP 摄像头接口

---

## 🆕 V2.0 新增功能

### 1. 场景感知状态机 (SceneStateMachine)

完整的多场景状态流转，每个状态有明确的进入/退出/保持条件：

```text
┌────────┐  手势启动  ┌───────────┐  距离变远  ┌─────────────┐
│  IDLE  │──────────▶│ FACE_MODE │──────────▶│ FUSION_MODE │
│  空闲  │           │  人脸模式  │◀──────────│  融合模式    │
└────────┘           └───────────┘  距离变近  └─────────────┘
    ▲                      │                         │
    │                      │ 人脸丢失                │ 距离变远
    │ 超时/手势停止         ▼                         ▼
┌──────────────┐     ┌───────────┐           ┌───────────┐
│ SEARCH_MODE  │◀────│ BODY_MODE │──────────▶│ BACK_MODE │
│   搜索模式    │     │  人体模式  │   转身     │  背对模式  │
└──────────────┘     └───────────┘◀──────────└───────────┘
```

**场景切换条件** (使用面积比例 + 置信度双条件，适配不同摄像头):

| 切换条件 | 人脸面积比例 | 置信度 | 说明 |
|---------|-------------|--------|-----|
| → FACE_MODE | ≥ 2% | ≥ 0.7 | 近距离正面 |
| → BODY_MODE | < 0.5% | - | 远距离 |
| → BACK_MODE | 无人脸 + body≥0.5 | body_sim≥0.6 | 背对目标 |

### 2. 光照归一化预处理

增强 ReID 特征在光照变化下的鲁棒性：

```python
# 处理流程
原始图像 → 灰度世界白平衡 → LAB空间CLAHE → 提取特征
```

配置项:
- `use_illumination_normalization`: 启用光照归一化
- `clahe_clip_limit`: CLAHE 对比度限制 (默认 2.0)
- `use_gray_world`: 灰度世界白平衡 (消除色偏)

### 3. 运动一致性增强

加入运动预测和步态周期特征：

- **运动预测**: 基于历史轨迹预测下一帧位置，排除突然跳变的误匹配
- **步态周期**: 通过 Y 坐标周期性波动估计步态频率，远距场景更稳定

```python
# 运动一致性计算
predicted_pos = current_pos + velocity * dt
consistency = 1 - distance(candidate, predicted) / allowed_deviation
```

### 4. 控制层安全优化

PID 控制器增加安全限制，避免近距场景电机过冲：

| 安全机制 | 参数 | 说明 |
|---------|------|-----|
| 加速度限制 | max_acceleration=0.3 | 平滑启停 |
| 速度限制 | max_velocity=0.8 | 防止失控 |
| 二阶滤波 | ω=10, ζ=0.7 | 去除高频抖动 |
| 死区处理 | deadzone=0.02 | 忽略微小误差 |

---

## ⚠️ S300 部署关键风险与修正

### 1. MediaPipe 无法在 S300 NPU 上运行 (Blocker)

**问题**: MediaPipe 的 TFLite 模型包含大量自定义算子，不支持 S300 NPU 的 Int8/Int16 算子集。

**建议替代方案**:

| 方案 | 描述 | 优点 | 缺点 |
|-----|------|------|-----|
| **方案 A (推荐)** | YOLOv5-Nano 多类别 (Person+Hand_Open+Hand_Fist) | 一次推理完成 | 需重新训练 |
| 方案 B | Nanodet-Hand + 分类头 | 算子兼容 | 需两次推理 |

### 2. ReID 算法计算载体

**问题**: 颜色直方图和 LBP 在 MCU (Cortex-M4) 上非常慢。

**建议**: 移植到 **DSP (SensPro 250)** 运行，利用向量指令集加速。

### 3. 模型量化精度

**问题**: MobileFaceNet 需要全整型量化，S300 NPU 不支持 FP16/FP32。

**建议**: 
- 全 INT8 量化，验证余弦相似度精度
- 如果最后一层损失严重，可切分到 DSP 以 FP32 运行

### 4. 串行推理延迟

**优化策略**:

| 策略 | 描述 | 效果 |
|-----|------|-----|
| 隔帧策略 | 人脸/识别每 5 帧跑一次 | 减少 60% 推理 |
| ROI 优化 | 只在人体框头部区域跑 SCRFD | 输入从 640→128 |
| 模型合并 | 人体+手势合并为一个模型 | 减少模型切换开销 |

---

## 🛠️ S300 部署架构建议

```text
┌─────────────────────────────────────────────────────────────────┐
│                        S300 部署流水线                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─────────┐    ┌──────────────────────────────────────────┐   │
│  │ DVP摄像头 │───▶│ DSP: 图像预处理 (缩放/格式转换)          │   │
│  └─────────┘    └──────────────────┬───────────────────────┘   │
│                                    │                            │
│                                    ▼                            │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │ NPU: YOLOv5 (人体+手势检测，合并模型)                      │   │
│  └──────────────────────────┬──────────────────────────────┘   │
│                              │                                  │
│          ┌───────────────────┼───────────────────┐              │
│          ▼                   ▼                   ▼              │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────────┐     │
│  │MCU: 逻辑判断 │    │DSP: 裁剪ROI │    │DSP: ReID特征提取│     │
│  │  (隔帧控制) │    │  (头部区域)  │    │ (颜色+LBP+几何) │     │
│  └──────┬──────┘    └──────┬──────┘    └────────┬────────┘     │
│         │                  │                    │               │
│         │                  ▼                    │               │
│         │         ┌─────────────┐               │               │
│         │         │NPU: SCRFD   │               │               │
│         │         │ (ROI人脸检测)│               │               │
│         │         └──────┬──────┘               │               │
│         │                │                      │               │
│         │                ▼                      │               │
│         │        ┌──────────────┐               │               │
│         │        │NPU: MobileFace│               │               │
│         │        │ (人脸识别)    │               │               │
│         │        └──────┬───────┘               │               │
│         │               │                       │               │
│         ▼               ▼                       ▼               │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ MCU: 多视角匹配 + 场景状态机 + PID控制                      │  │
│  └──────────────────────────────────────────────────────────┘  │
│                              │                                  │
│                              ▼                                  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ MCU: 输出控制信号 (云台PWM / 机器人轮速)                    │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 📝 开发路线图

- [x] 基础跟随功能
- [x] 多视角识别
- [x] 场景感知状态机
- [x] 光照归一化
- [x] 运动一致性
- [x] 控制层安全优化
- [ ] YOLOv5 多类别训练 (人+手势)
- [ ] DSP C/C++ 移植
- [ ] NPU INT8 量化验证
- [ ] 云台/机器人控制接口
